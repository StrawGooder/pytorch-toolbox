{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take in a model with linear layer which say works for image of resolution 3x224x224\n",
    "# Convert it into a spatial model which can now work on any image size\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features', Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (1): ReLU (inplace)\n",
      "  (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU (inplace)\n",
      "  (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU (inplace)\n",
      "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU (inplace)\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU (inplace)\n",
      "  (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "))\n",
      "('classifier', Sequential (\n",
      "  (0): Dropout (p = 0.5)\n",
      "  (1): Linear (9216 -> 4096)\n",
      "  (2): ReLU (inplace)\n",
      "  (3): Dropout (p = 0.5)\n",
      "  (4): Linear (4096 -> 4096)\n",
      "  (5): ReLU (inplace)\n",
      "  (6): Linear (4096 -> 1000)\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "m1 = models.alexnet(pretrained=True)  # pretrained alexnet model\n",
    "m1.eval()\n",
    "for (name, layer) in m1._modules.items():\n",
    "    #iteration over outer layers\n",
    "    print((name, layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelDef(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ModelDef, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),                                \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(256, 4096, kernel_size=6),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(4096, 4096, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        )                                                         \n",
    "                                                                  \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features', Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (1): ReLU (inplace)\n",
      "  (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU (inplace)\n",
      "  (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU (inplace)\n",
      "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU (inplace)\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU (inplace)\n",
      "  (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "))\n",
      "('classifier', Sequential (\n",
      "  (0): Dropout (p = 0.5)\n",
      "  (1): Conv2d(256, 4096, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (2): ReLU (inplace)\n",
      "  (3): Dropout (p = 0.5)\n",
      "  (4): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): ReLU (inplace)\n",
      "  (6): Conv2d(4096, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "m2 = ModelDef()\n",
    "m2.eval()\n",
    "for (name, layer) in m2._modules.items():\n",
    "    #iteration over outer layers\n",
    "    print((name, layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.7129 -0.3940  0.5958 -0.7427 -0.9551 -1.0343\n",
      "  1.0163  1.0155 -0.0219 -0.8092  0.4064 -0.3752\n",
      "  0.9636  0.7135 -0.9375  0.8450  0.1269  0.6673\n",
      "  0.8593  1.0271  0.6331  1.0400  0.4612 -0.1184\n",
      " -0.5954 -0.3229 -0.4763 -0.1278  0.4813 -0.6584\n",
      "  0.1439 -1.0080 -0.8007  0.0180 -0.1923 -0.1401\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.9219\n",
      " -0.0723\n",
      " -1.0670\n",
      " -2.1309\n",
      " -0.8962\n",
      " -2.0367\n",
      " -1.0963\n",
      " -1.1400\n",
      " -1.0789\n",
      " -0.9955\n",
      " -0.5506\n",
      " -0.5041\n",
      " -2.1386\n",
      " -0.7569\n",
      " -2.2493\n",
      " -0.7488\n",
      " -1.8975\n",
      " -1.0458\n",
      " -1.7070\n",
      " -0.2994\n",
      " -0.1663\n",
      " -0.0909\n",
      " -0.8320\n",
      " -0.3444\n",
      " -1.1933\n",
      "  0.3273\n",
      "  0.2165\n",
      "  0.2178\n",
      " -0.1997\n",
      " -0.5213\n",
      " -0.4225\n",
      " -0.1865\n",
      " -0.8689\n",
      " -0.6569\n",
      " -0.3979\n",
      " -0.3722\n",
      "[torch.FloatTensor of size 36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m2._modules['classifier'][1].weight[1][1])\n",
    "print(m1._modules['classifier'][1].weight[1][36:72]) # Weights of the models are different at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-8.7606e+28\n",
      "-2.1060e+27\n",
      "-1.2613e+28\n",
      "-1.2498e+29\n",
      "-4.9750e+28\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      "-2.6316e+26\n",
      "-2.3292e+26\n",
      "-1.7740e+26\n",
      " 3.5361e+26\n",
      "-2.8206e+25\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.FloatTensor(1, 3, 224, 224))\n",
    "y1 = m1(x)\n",
    "y2 = m2(x)\n",
    "print(y1[0, :5])\n",
    "print(y2[0, :5, 0, 0])  # Different output values; as expected!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j in zip(m1.modules(), m2.modules()):\n",
    "    if not list(i.children()):\n",
    "        if isinstance(i, nn.Linear):  # copy weights of linear layer into conv2d\n",
    "            j.weight.data = i.weight.data.view(j.weight.size())\n",
    "            j.bias.data = i.bias.data\n",
    "        else:\n",
    "            if len(i.state_dict()) > 0:  # relu and dropout do not have anything in their state_dict\n",
    "                j.weight.data = i.weight.data\n",
    "                j.bias.data = i.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.3969 -0.8168 -0.3132  0.0382 -1.2532 -0.7787\n",
      " -0.5779 -0.6933  0.1444  0.3889 -0.5300  0.1078\n",
      " -0.0160 -0.5410  0.3189 -0.1015 -0.3006 -0.1682\n",
      " -0.8105  0.4949 -0.0498  0.6025 -0.7505 -0.4757\n",
      " -0.8852 -0.7535 -0.7075  0.5752  0.2680 -1.7264\n",
      "  0.3389 -0.7997  0.4491  1.4019  0.5940  0.2137\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -0.3969\n",
      " -0.8168\n",
      " -0.3132\n",
      "  0.0382\n",
      " -1.2532\n",
      " -0.7787\n",
      " -0.5779\n",
      " -0.6933\n",
      "  0.1444\n",
      "  0.3889\n",
      " -0.5300\n",
      "  0.1078\n",
      " -0.0160\n",
      " -0.5410\n",
      "  0.3189\n",
      " -0.1015\n",
      " -0.3006\n",
      " -0.1682\n",
      " -0.8105\n",
      "  0.4949\n",
      " -0.0498\n",
      "  0.6025\n",
      " -0.7505\n",
      " -0.4757\n",
      " -0.8852\n",
      " -0.7535\n",
      " -0.7075\n",
      "  0.5752\n",
      "  0.2680\n",
      " -1.7264\n",
      "  0.3389\n",
      " -0.7997\n",
      "  0.4491\n",
      "  1.4019\n",
      "  0.5940\n",
      "  0.2137\n",
      "[torch.FloatTensor of size 36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m2._modules['classifier'][1].weight[0][1])\n",
    "print(m1._modules['classifier'][1].weight[0][36:72]) # Weights of both the models are now exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-8.7606e+28\n",
      "-2.1060e+27\n",
      "-1.2613e+28\n",
      "-1.2498e+29\n",
      "-4.9750e+28\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      "-8.7606e+28\n",
      "-2.1060e+27\n",
      "-1.2613e+28\n",
      "-1.2498e+29\n",
      "-4.9750e+28\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y1 = m1(x)\n",
    "y2 = m2(x)\n",
    "print(y1[0][:5])\n",
    "print(y2[0, :5, 0, 0])  # Same output values as expected!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = Variable(torch.FloatTensor(1, 3, 300, 300))\n",
    "y2 = m2(x1)\n",
    "print(y2.size())       # Now the network is capable of giving spatial output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
